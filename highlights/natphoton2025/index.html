<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Towards the ultimate limits of artificial neural networks | Waves Physics &amp; Information in Complex Systems </title> <meta name="author" content="Dorian Bouchet"> <meta name="description" content="We are an experimental physics group located in Grenoble working on the propagation of waves in complex scattering media. "> <meta name="keywords" content="waves, scattering, light, information"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/emowave.png?9a198e2fddbc6b087a33da085493510f"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dbouchet.github.io/highlights/natphoton2025/"> <script src="/assets/js/theme.js?c2bf737e2df504c0dfba92abe80f8fe1"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Waves Physics &amp; Information in Complex Systems </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item active"> <a class="nav-link" href="/highlights/">Highlights <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/team/">Team </a> </li> <li class="nav-item "> <a class="nav-link" href="/collaborations/">Collaborations </a> </li> <li class="nav-item "> <a class="nav-link" href="/openings/">Openings </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Towards the ultimate limits of artificial neural networks</h1> <p class="post-description"></p> </header> <article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/highlights/natphoton2025_highres-480.webp 480w,/assets/img/highlights/natphoton2025_highres-800.webp 800w,/assets/img/highlights/natphoton2025_highres-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/highlights/natphoton2025_highres.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Artistic representation of an optical measurement in a complex scattering system. Optical information is collected by a camera chip and digitally processed by an artificial neural network. Image credit: oliver-diekmann.graphics. </div> <p align="justify"> <b> When light is scattered, how precisely can a measurement result be inferred from this light? We explored the limits of what is possible using artificial intelligence. </b> </p> <p align="justify"> No image is infinitely sharp: no matter how precisely you build a microscope or a camera, there are always fundamental precision limits that cannot be exceeded in principle. For example, the position of a particle can never be measured with infinite precision; a certain amount of uncertainty is unavoidable. This limit does not result from technical weaknesses, but from the physical properties of light and from the transmission of information itself. </p> <p align="justify"> We therefore posed the question: What is the absolute precision limit that is possible with optical measurement methods? And how can this limit be approached as closely as possible? We succeeded in calculating the ultimate limit for the theoretically achievable precision, and also managed to develop artificial neural networks that come close to this limit after appropriate training. This strategy is now to be used in imaging processes, for example in biomedical imaging applications. </p> <p align="justify"> <b> An ultimate limit to measurement precision </b> </p> <p align="justify"> To illustrate how challenging optical imaging can be, we can imagine that we are looking at a small object located behind a shower curtain. Because of random light scattering by the curtain, we do not just see an image of the object, but a complicated light pattern consisting of many lighter and darker patches of light. The question now is: how precisely can we estimate where the object actually is based on this image, and what is the ultimate limit to the achievable precision? </p> <p align="justify"> Such scenarios are especially important in biophysics and medical imaging. Indeed, when light is scattered by biological tissues, it appears to lose information about deeper tissue structures. But how much of this information can be recovered in principle? This question is not only of a technical nature, but physics itself sets a fundamental limit here. </p> <p align="justify"> The answer to this is provided by a theoretical measure: the so-called Fisher information. It describes how much information a noisy optical signal contains about an unknown parameter, such as the object position. If the Fisher information is low, a precise determination of the parameter value is not possible, no matter how sophisticatedly the signal is analyzed. Based on the Fisher information, we were able to calculate an upper limit for the theoretically achievable precision in optical experiments. </p> <p align="justify"> <b> Neural networks can learn from chaotic light patterns </b> </p> <p align="justify"> In a proof-of-principle experiment that we conducted, a laser beam was directed at a small, reflective object. This object was located behind a turbid liquid, so that the recorded images only showed highly distorted light patterns. The measurement conditions varied depending on the turbidity: the larger the turbidity, the greater the difficulty of obtaining precise position information from the measured signal. </p> <p align="justify"> To the human eye, these images looked like random patterns. But by feeding many such images (each with a known object position) into a neural network, the network could learn which patterns were associated with which positions. After sufficient training, the network was able to determine the object position very precisely, even with new, unknown patterns. </p> <p align="justify"> <b> A precision close to the physical limit </b> </p> <p align="justify"> Particularly noteworthy: the precision of the network predictions was only slightly worse than the theoretically achievable precision calculated using Fisher information. This means that the artificial neural networks implemented in this study were not only effective, but also almost optimal, as they came close to the ultimate precision that is permitted by the laws of physics. </p> <p align="justify"> This realization has far-reaching consequences: with the help of intelligent algorithms, optical measurement methods could be significantly improved in a wide range of areas - from medical diagnostics to materials research and quantum technology. In future projects, we want to work with partners from applied physics and medicine to investigate how these AI-supported methods can be used in specific systems. </p> <p align="justify"> This study has been published in Nature Photonics <a class="citation" href="#starshynov_model-free_2025">(Starshynov et al., 2025)</a>. </p> </article> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publications/NatPhoton_s41566-025-01657-6-480.webp 480w,/assets/img/publications/NatPhoton_s41566-025-01657-6-800.webp 800w,/assets/img/publications/NatPhoton_s41566-025-01657-6-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publications/NatPhoton_s41566-025-01657-6.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="NatPhoton_s41566-025-01657-6.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="starshynov_model-free_2025" class="col-sm-8"> <div class="title">Model-free estimation of the Cramér–Rao bound for deep learning microscopy in complex media</div> <div class="author"> Ilya Starshynov, Maximilian Weimar, Lukas M. Rachbauer, Günther Hackl, Daniele Faccio, Stefan Rotter, and Dorian Bouchet </div> <div class="periodical"> <em>Nature Photonics</em> <span style="font-weight: 400;">15</span>, 10275 (May 2025) </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1038/s41566-025-01657-6" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://rdcu.be/eoaSv" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/publications/NatPhoton_s41566-025-01657-6_SI.pdf" class="btn btn-sm z-depth-0" role="button">Supp</a> </div> <div class="abstract hidden"> <p>Artificial neural networks have become important tools to harness the complexity of disordered or random photonic systems. Recent applications include the recovery of information from light that has been scrambled during propagation through a complex scattering medium, especially in the challenging case in which the deterministic input–output transmission matrix cannot be measured. This naturally raises the question of what the limit is that information theory imposes on this recovery process, and whether neural networks can actually reach this limit. To answer these questions, we introduce a model-free approach to calculate the Cramér–Rao bound, which sets the ultimate precision limit at which artificial neural networks can operate. As an example, we apply this approach in a proof-of-principle experiment using laser light propagating through a disordered medium, evidencing that a convolutional network approaches the ultimate precision limit in the challenging task of localizing a reflective target hidden behind a dynamically fluctuating scattering medium. The model-free method introduced here is generally applicable to benchmark the performance of any deep learning microscope, to drive algorithmic developments and to push the precision of metrology and imaging techniques to their ultimate limit.</p> </div> </div> </div> </li></ol> </div> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?3e7054dc4d3e3dd8f0731a48453e618e"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?3577194613afa04501eb52f8f4164de9" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>